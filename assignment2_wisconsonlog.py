# -*- coding: utf-8 -*-
"""Assignment2_wisconsonLog.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yd6DQV18l3hpU-kdr3cH-pcjy__5y5P_
"""

!pip uninstall pandas-profiling

!pip install pandas-profiling

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Define column names
column_names = [
    "ID", "Diagnosis", "Radius_mean", "Texture_mean", "Perimeter_mean", "Area_mean", "Smoothness_mean",
    "Compactness_mean", "Concavity_mean", "Concave_points_mean", "Symmetry_mean", "Fractal_dimension_mean",
    "Radius_se", "Texture_se", "Perimeter_se", "Area_se", "Smoothness_se", "Compactness_se", "Concavity_se",
    "Concave_points_se", "Symmetry_se", "Fractal_dimension_se", "Radius_worst", "Texture_worst", "Perimeter_worst",
    "Area_worst", "Smoothness_worst", "Compactness_worst", "Concavity_worst", "Concave_points_worst", "Symmetry_worst",
    "Fractal_dimension_worst"
]

# Load the dataset again (for a fresh start)
data = pd.read_csv('./wdbc.data', names=column_names)

# Display the first few rows of the dataset
print(data.head())

# Drop the ID column
data = data.drop(columns=['ID'])

"""Performing EDA on the Data Set and Converting the"""

# Convert the Diagnosis column to numerical values
data['Diagnosis'] = data['Diagnosis'].map({'M': 1, 'B': 0})

# Basic statistical summary
basic_summary = data.describe()

# Distribution plots for selected features
selected_features = ['Radius_mean', 'Texture_mean', 'Perimeter_mean', 'Area_mean']
plt.figure(figsize=(15, 10))
for i, feature in enumerate(selected_features):
    plt.subplot(2, 2, i + 1)
    sns.histplot(data[feature], kde=True)
    plt.title(f'Distribution of {feature}')
plt.tight_layout()
plt.show()

# Correlation matrix
corr_matrix = data.corr()

# Heatmap of the correlation matrix
plt.figure(figsize=(18, 15))
sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Heatmap of Feature Correlations')
plt.show()

# Pair plot for selected features
sns.pairplot(data, vars=selected_features, hue='Diagnosis', markers=["o", "s"])
plt.suptitle('Pair Plot of Selected Features', y=1.02)
plt.show()

basic_summary, corr_matrix

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report


# # Convert the Diagnosis column to numerical values
# data['Diagnosis'] = data['Diagnosis'].map({'M': 1, 'B': 0})

# Separate features and target
X = data.drop(columns=['Diagnosis'])
y = data['Diagnosis']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Logistic Regression model
model = LogisticRegression(max_iter=10000)
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print("Classification Report:")
print(class_report)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False,
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()